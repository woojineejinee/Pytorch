{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.5 모델 훈련\n",
    "\n",
    "# 딥러닝에서 학습을 시킨다는 것은 y = w(가중치)x(입력) + b(편향)라는 함수에서\n",
    "# w와 b의 적절한 값을 찾는다는 의미이다. w와 b에 임의 값을 적용하여 시작하며\n",
    "# 오차가 줄어들어 전역 최소점에 이를 때까지 파라미터(w, b)를 계속 수정한다.\n",
    "\n",
    "# 구체적으로 훈련 방법에 대해 알아보자면 가장 먼저 필요한 절차가\n",
    "# optimizer,zero_grad() 메서드를 이용하여 기울기를 초기화하는 것이다.\n",
    "# 파이토치는 기울기 값을 계산하기 위해 loss.backward() 메서드를 이용하는데,\n",
    "# 이 메서드을 사용하면 새로운 기울기 값이 이전 기울기 값에 누적하여 계산된다.\n",
    "# 이 방법은 순환신경망(RNN) 모델을 구현할 때 효과적이지만 누적 계산이 필요하지\n",
    "# 않는 모델에 대해서는 불필요하다. 따라서 기울기 값에 대해 누적 계산이 필요하지\n",
    "# 않을 때는 입력값을 모델에 적용하기 전에 optimizer.zero_grad() 메서드를\n",
    "# 호출하여 미분 값(기울기를 구하는 과정에서 미분을 사용)이 누적되지 않게\n",
    "# 초기화해 주어야 합니다. 다음은 loss.backward() 메서드를 이용하여 기울기를 자동 계산한다.\n",
    "# loss.backward()는 배치가 반복될 때마다 오차가 중첩적으로 쌓이게 되므로 매번\n",
    "# zero_grad()를 사용하여 미분 값을 0으로 초기화한다.\n",
    "\n",
    "# 파이토치 학습 절차\n",
    "# - 모델, 손실 함수, 옵티마이저 정의\n",
    "# - optimizer.zero_grad() : 전방향 학습, 기울기 초기화\n",
    "# - output = model(input) : 출력 계산\n",
    "# - loss = loss_fn(output, target) : 오차 계산\n",
    "# - loss.backward() : 역전파 학습\n",
    "# - optimizer.step() : 기울기 업데이트\n",
    "\n",
    "# 아래는 모델을 훈련시키는 예시 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    yhat = model(x_train)\n",
    "    loss = criterion(yhat, y_train)\n",
    "    optimizer.zero_grad() # 오차가 중첩적으로 쌓이지 않도록 초기화\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af11ccc323831c87a8534a1ec73f2a239ff9f33c1dde9ab31b1585326fc75cb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
